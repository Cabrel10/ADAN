# Guide d'Ex√©cution Complet - ADAN Trading Bot

## üìã Table des Mati√®res

1. [Pr√©requis](#pr√©requis)
2. [Installation et Configuration](#installation-et-configuration)
3. [Pipeline d'Ex√©cution CPU](#pipeline-dex√©cution-cpu)
4. [Pipeline d'Ex√©cution GPU](#pipeline-dex√©cution-gpu)
5. [V√©rification et Validation](#v√©rification-et-validation)
6. [Troubleshooting](#troubleshooting)
7. [Monitoring et Analyse](#monitoring-et-analyse)

---

## üîß Pr√©requis

### Syst√®me Requis
- **CPU** : Ubuntu 20.04+ ou √©quivalent, 8GB+ RAM, Python 3.11
- **GPU** : Ubuntu 20.04+, 32GB+ RAM, GTX 1650+, CUDA 11.8+, Python 3.11

### D√©pendances
```bash
# Installation de Miniconda (si n√©cessaire)
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# Initialisation de conda
source ~/.bashrc
conda init
```

---

## üõ†Ô∏è Installation et Configuration

### 1. Clone et Setup Initial
```bash
# Cloner le projet
git clone <ADAN_REPOSITORY_URL>
cd ADAN

# Cr√©er l'environnement conda
conda create -n trading_env python=3.11 -y
conda activate trading_env

# Installer les d√©pendances
pip install -r requirements.txt
```

### 2. Configuration Sp√©cifique GPU (Uniquement pour GPU)
```bash
# V√©rifier CUDA
nvidia-smi
nvcc --version

# Installer PyTorch avec support CUDA (ajuster selon votre version CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# V√©rifier l'installation GPU
python -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Aucun\"}')"
```

### 3. V√©rification de l'Installation
```bash
# Test des imports critiques
python -c "
import pandas as pd
import numpy as np
import gymnasium as gym
import stable_baselines3 as sb3
import ccxt
import pandas_ta as ta
print('‚úÖ Toutes les d√©pendances sont install√©es correctement')
"
```

---

## üíª Pipeline d'Ex√©cution CPU

### √âtape 1 : Nettoyage (Optionnel)
```bash
# Activer l'environnement
conda activate trading_env
cd ADAN

# Nettoyage complet (optionnel pour nouveau d√©marrage)
find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
find . -name "*.pyc" -delete 2>/dev/null || true
rm -rf data/processed/* data/scalers_encoders/* 2>/dev/null || true
```

### √âtape 2 : Collecte des Donn√©es
```bash
# T√©l√©charger les donn√©es de march√©
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/fetch_data_ccxt.py --exec_profile cpu
```
**Dur√©e estim√©e :** 5-10 minutes  
**V√©rification :** `ls -la data/raw/` doit contenir 15 fichiers .parquet (5 assets √ó 3 timeframes)

### √âtape 3 : Traitement des Donn√©es
```bash
# Traiter les donn√©es (calcul des indicateurs techniques)
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/process_data.py --exec_profile cpu
```
**Dur√©e estim√©e :** 2-5 minutes  
**V√©rification :** `ls -la data/processed/` doit contenir 5 dossiers d'assets

### √âtape 4 : Fusion des Donn√©es
```bash
# Fusionner les donn√©es multi-assets
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/merge_processed_data.py --exec_profile cpu
```
**Dur√©e estim√©e :** 1-2 minutes  
**V√©rification :** `ls -la data/processed/merged/` doit contenir 12 fichiers .parquet

### √âtape 5 : Validation du Pipeline
```bash
# Test court pour valider le pipeline
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile cpu --device cpu --initial_capital 15 --total_timesteps 100
```
**Dur√©e estim√©e :** 1-2 minutes  
**V√©rification :** Aucune erreur, logs indiquent "Training completed successfully!"

### √âtape 6 : Entra√Ænement Principal CPU
```bash
# Entra√Ænement de production CPU
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile cpu --device cpu --initial_capital 15 --total_timesteps 200000
```
**Dur√©e estim√©e :** 2-4 heures  
**Fichiers g√©n√©r√©s :** `models/final_model.zip`, logs dans `reports/tensorboard_logs/`

---

## üöÄ Pipeline d'Ex√©cution GPU

### √âtape 1 : Nettoyage et Pr√©paration GPU
```bash
# Activer l'environnement
conda activate trading_env
cd ADAN

# Nettoyage complet (recommand√© pour GPU)
find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
find . -name "*.pyc" -delete 2>/dev/null || true
rm -rf data/processed/* data/scalers_encoders/* 2>/dev/null || true

# V√©rification GPU finale
nvidia-smi
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### √âtape 2 : Collecte des Donn√©es GPU (Maximis√©e)
```bash
# T√©l√©charger les donn√©es √©tendues pour GPU
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/fetch_data_ccxt.py --exec_profile gpu
```
**Dur√©e estim√©e :** 15-30 minutes (plus de donn√©es historiques)  
**V√©rification :** `ls -la data/raw/` avec fichiers plus volumineux

### √âtape 3 : Traitement GPU
```bash
# Traitement optimis√© GPU
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/process_data.py --exec_profile gpu
```
**Dur√©e estim√©e :** 5-10 minutes  
**V√©rification :** V√©rifier l'absence d'erreurs dans les logs

### √âtape 4 : Fusion GPU
```bash
# Fusion pour configuration GPU
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/merge_processed_data.py --exec_profile gpu
```
**Dur√©e estim√©e :** 2-5 minutes  
**V√©rification :** Fichiers plus volumineux dans `data/processed/merged/`

### √âtape 5 : Test de Validation GPU
```bash
# Test court GPU
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile gpu --device cuda --initial_capital 15 --total_timesteps 500
```
**Dur√©e estim√©e :** 2-3 minutes  
**V√©rification :** Utilisation GPU visible avec `nvidia-smi`

### √âtape 6 : Entra√Ænement Principal GPU (Production)
```bash
# Entra√Ænement intensif GPU - 2M timesteps avec 8 workers
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile gpu --device cuda --initial_capital 15 --total_timesteps 2000000
```
**Dur√©e estim√©e :** 8-12 heures  
**Configuration :** 8 environnements parall√®les, batch_size=512, fen√™tre CNN=30

---

## ‚úÖ V√©rification et Validation

### V√©rifications Critiques √† Chaque √âtape

#### Apr√®s Collecte des Donn√©es
```bash
# V√©rifier les fichiers raw
python -c "
import pandas as pd
import os
assets = ['DOGEUSDT', 'XRPUSDT', 'LTCUSDT', 'SOLUSDT', 'ADAUSDT']
timeframes = ['1m', '1h', '1d']
for asset in assets:
    for tf in timeframes:
        file = f'data/raw/{asset}_{tf}_raw.parquet'
        if os.path.exists(file):
            df = pd.read_parquet(file)
            print(f'‚úÖ {file}: {len(df)} lignes')
        else:
            print(f'‚ùå {file}: MANQUANT')
"
```

#### Apr√®s Traitement
```bash
# V√©rifier la structure des donn√©es trait√©es
python -c "
import pandas as pd
import os
# Test sur un fichier trait√©
df = pd.read_parquet('data/processed/DOGEUSDT/DOGEUSDT_1h_train.parquet')
print(f'Shape: {df.shape}')
print(f'Colonnes: {list(df.columns)}')
# Doit avoir 19 colonnes : 5 OHLCV + 14 indicateurs
assert df.shape[1] == 19, f'Expected 19 columns, got {df.shape[1]}'
print('‚úÖ Structure correcte')
"
```

#### Apr√®s Fusion
```bash
# V√©rifier la fusion multi-assets
python -c "
import pandas as pd
df = pd.read_parquet('data/processed/merged/1h_train_merged.parquet')
print(f'Shape: {df.shape}')
print(f'Colonnes (30 premi√®res): {list(df.columns[:30])}')
# Doit avoir 95 colonnes : 19 features √ó 5 assets
assert df.shape[1] == 95, f'Expected 95 columns, got {df.shape[1]}'
print('‚úÖ Fusion correcte - 95 colonnes')
"
```

### Validation StateBuilder (Critical)
```bash
# Test crucial - v√©rifier que StateBuilder trouve toutes les features
python -c "
import sys
sys.path.append('src')
from adan_trading_bot.common.utils import load_config, get_path
import pandas as pd
import os

# Charger la config
data_config = load_config(os.path.join(get_path('config'), 'data_config_cpu.yaml'))
base_features = data_config['base_market_features']
assets = data_config['assets']

# Charger donn√©es fusionn√©es
df = pd.read_parquet('data/processed/merged/1h_train_merged.parquet')

# V√©rifier chaque feature pour chaque asset
missing_features = []
for feature in base_features:
    for asset in assets:
        column_name = f'{feature}_{asset}'
        if column_name not in df.columns:
            missing_features.append(column_name)

if missing_features:
    print(f'‚ùå Features manquantes: {missing_features}')
    exit(1)
else:
    print(f'‚úÖ Toutes les {len(base_features) * len(assets)} features trouv√©es')
"
```

---

## üö® Troubleshooting

### Probl√®mes Courants

#### 1. Erreur "FEATURE NON TROUV√âE"
```bash
# Diagnostic
python -c "
import pandas as pd
df = pd.read_parquet('data/processed/DOGEUSDT/DOGEUSDT_1h_train.parquet')
print('Colonnes dans le fichier trait√©:')
for i, col in enumerate(df.columns):
    print(f'{i+1}. {col}')
"

# Solution : V√©rifier base_market_features dans config/data_config_cpu.yaml
```

#### 2. Erreur CUDA/GPU
```bash
# Diagnostic GPU
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# Si False, r√©installer PyTorch avec CUDA
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 3. Erreur Rich (affichage corrompu)
```bash
# Solution : Toujours utiliser les variables d'environnement
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/...
```

#### 4. Erreur de m√©moire GPU
```bash
# R√©duire batch_size dans config/agent_config_gpu.yaml
# batch_size: 512 -> 256 -> 128
# ou r√©duire n_steps: 4096 -> 2048
```

#### 5. Probl√®me de chemins
```bash
# Test des chemins
python -c "
import sys
sys.path.append('src')
from adan_trading_bot.common.utils import get_project_root, get_path
print(f'Root: {get_project_root()}')
print(f'Data: {get_path(\"data\")}')
"
```

---

## üìä Monitoring et Analyse

### Monitoring en Temps R√©el

#### Terminal 1 : Entra√Ænement
```bash
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile gpu --device cuda --initial_capital 15 --total_timesteps 2000000
```

#### Terminal 2 : Monitoring GPU (si GPU)
```bash
watch -n 1 nvidia-smi
```

#### Terminal 3 : TensorBoard
```bash
conda activate trading_env
cd ADAN
tensorboard --logdir reports/tensorboard_logs --host 0.0.0.0 --port 6006
```
**Acc√®s :** http://localhost:6006

### M√©triques Cl√©s √† Surveiller

#### TensorBoard
- **rollout/ep_rew_mean** : R√©compense moyenne par √©pisode (doit augmenter)
- **rollout/ep_len_mean** : Dur√©e moyenne des √©pisodes
- **train/policy_loss** : Perte de la politique (doit diminuer)
- **train/value_loss** : Perte de la fonction de valeur
- **train/entropy_loss** : Entropie (exploration vs exploitation)

#### Logs de Trading
- **Capital Evolution** : Progression du capital
- **Positions Prises** : Fr√©quence et types d'ordres
- **PnL par Trade** : Performance des trades individuels

### Analyse Post-Entra√Ænement
```bash
# V√©rifier les mod√®les g√©n√©r√©s
ls -la models/
# Fichiers attendus : final_model.zip, checkpoints/, best_model/

# Analyser les logs
tail -100 training_log.txt

# √âvaluer les performances
python -c "
import os
model_files = [f for f in os.listdir('models/') if f.endswith('.zip')]
print(f'Mod√®les g√©n√©r√©s: {model_files}')
"
```

---

## üéØ Commandes de R√©f√©rence Rapide

### CPU - Pipeline Complet
```bash
conda activate trading_env && cd ADAN
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/fetch_data_ccxt.py --exec_profile cpu
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/process_data.py --exec_profile cpu
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/merge_processed_data.py --exec_profile cpu
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile cpu --device cpu --initial_capital 15 --total_timesteps 200000
```

### GPU - Pipeline Complet
```bash
conda activate trading_env && cd ADAN
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/fetch_data_ccxt.py --exec_profile gpu
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/process_data.py --exec_profile gpu
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/merge_processed_data.py --exec_profile gpu
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile gpu --device cuda --initial_capital 15 --total_timesteps 2000000
```

### Test Rapide (Validation)
```bash
TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1 python scripts/train_rl_agent.py --exec_profile cpu --device cpu --initial_capital 15 --total_timesteps 100
```

---

## üìù Notes Importantes

- **TOUJOURS** utiliser `TERM=dumb PYTHONIOENCODING=utf-8 PYTHONUNBUFFERED=1` pour √©viter les probl√®mes d'affichage Rich
- **GPU** : Surveiller la VRAM avec `nvidia-smi` pendant l'entra√Ænement
- **Interruption** : Ctrl+C sauvegarde automatiquement le mod√®le (`interrupted_model.zip`)
- **Reproductibilit√©** : Seed fix√© √† 42 dans les configurations
- **Checkpoints** : Sauvegarde automatique tous les 50k (CPU) / 200k (GPU) timesteps

---

**‚úÖ En suivant ce guide, vous devriez obtenir un agent ADAN fonctionnel entra√Æn√© sur des donn√©es multi-assets avec indicateurs techniques sp√©cifiques par timeframe.**