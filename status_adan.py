#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script de statut complet pour ADAN v2.1.
Affiche l'√©tat du syst√®me, performances, exchange integration et apprentissage continu.
"""
import os
import sys
import time
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path

# Rich imports
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.columns import Columns
from rich.text import Text
from rich.progress import Progress, BarColumn, TextColumn
from rich.tree import Tree
from rich.rule import Rule

# Ajouter le r√©pertoire parent au path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

console = Console()

def check_online_learning_capabilities():
    """V√©rifie les capacit√©s d'apprentissage continu."""
    learning_status = {
        "scripts_available": False,
        "config_ready": False,
        "models_compatible": False,
        "buffer_support": False
    }
    
    # Scripts d'apprentissage continu
    learning_scripts = [
        "scripts/paper_trade_agent.py",
        "scripts/online_learning_agent.py", 
        "scripts/human_feedback_trading.py"
    ]
    
    learning_status["scripts_available"] = all(os.path.exists(script) for script in learning_scripts)
    
    # Configuration apprentissage continu
    config_files = [
        "config/main_config.yaml",
        "GUIDE_APPRENTISSAGE_CONTINU.md"
    ]
    
    learning_status["config_ready"] = all(os.path.exists(config) for config in config_files)
    
    # Mod√®les disponibles
    models_dir = Path("models")
    if models_dir.exists():
        model_files = list(models_dir.glob("*.zip"))
        learning_status["models_compatible"] = len(model_files) > 0
    
    # Support technique
    learning_status["buffer_support"] = os.path.exists("src/adan_trading_bot/exchange_api")
    
    return learning_status

def check_conda_env():
    """V√©rifie l'environnement conda."""
    try:
        result = subprocess.run("conda info --envs | grep trading_env", 
                               shell=True, capture_output=True, text=True)
        return result.returncode == 0
    except:
        return False

def check_exchange_connection():
    """V√©rifie la connexion exchange."""
    exchange_status = {
        "api_key_set": False,
        "secret_key_set": False,
        "connection_test": False,
        "markets_loaded": False
    }
    
    # V√©rifier variables d'environnement
    api_key = os.environ.get("BINANCE_TESTNET_API_KEY")
    secret_key = os.environ.get("BINANCE_TESTNET_SECRET_KEY")
    
    exchange_status["api_key_set"] = bool(api_key)
    exchange_status["secret_key_set"] = bool(secret_key)
    
    if api_key and secret_key:
        try:
            # Test de connexion rapide
            result = subprocess.run("python test_exchange_connector.py", 
                                   shell=True, capture_output=True, text=True, timeout=30)
            exchange_status["connection_test"] = result.returncode == 0
            
            if result.returncode == 0:
                exchange_status["markets_loaded"] = "markets loaded" in result.stdout.lower()
        except:
            exchange_status["connection_test"] = False
    
    return exchange_status

def check_data_files():
    """V√©rifie les fichiers de donn√©es."""
    data_status = {}
    
    # Donn√©es source
    source_files = [
        "data/new/ADAUSDT_features.parquet",
        "data/new/BNBUSDT_features.parquet", 
        "data/new/BTCUSDT_features.parquet",
        "data/new/ETHUSDT_features.parquet",
        "data/new/XRPUSDT_features.parquet"
    ]
    
    # Donn√©es processed multi-timeframe
    processed_files = [
        "data/processed/unified/1m_train_merged.parquet",
        "data/processed/unified/1m_val_merged.parquet",
        "data/processed/unified/1m_test_merged.parquet",
        "data/processed/unified/1h_train_merged.parquet",
        "data/processed/unified/1d_train_merged.parquet"
    ]
    
    # Scalers pour apprentissage continu
    scaler_files = [
        "data/scalers_encoders/scaler_1m.joblib",
        "data/scalers_encoders/scaler_1h.joblib",
        "data/scalers_encoders/scaler_1d.joblib"
    ]
    
    data_status['source'] = {
        'files': len([f for f in source_files if os.path.exists(f)]),
        'total': len(source_files),
        'size_mb': sum(os.path.getsize(f)/(1024*1024) for f in source_files if os.path.exists(f))
    }
    
    data_status['processed'] = {
        'files': len([f for f in processed_files if os.path.exists(f)]),
        'total': len(processed_files),
        'size_mb': sum(os.path.getsize(f)/(1024*1024) for f in processed_files if os.path.exists(f))
    }
    
    data_status['scalers'] = {
        'files': len([f for f in scaler_files if os.path.exists(f)]),
        'total': len(scaler_files),
        'size_mb': sum(os.path.getsize(f)/(1024*1024) for f in processed_files if os.path.exists(f))
    }
    
    return data_status

def check_config_files():
    """V√©rifie les fichiers de configuration."""
    config_files = [
        "config/main_config.yaml",
        "config/data_config_cpu.yaml",
        "config/data_config_gpu.yaml", 
        "config/agent_config_cpu.yaml",
        "config/agent_config_gpu.yaml",
        "config/environment_config.yaml",
        "config/logging_config.yaml"
    ]
    
    status = {}
    for config_file in config_files:
        status[os.path.basename(config_file)] = {
            'exists': os.path.exists(config_file),
            'size': os.path.getsize(config_file) if os.path.exists(config_file) else 0,
            'modified': datetime.fromtimestamp(os.path.getmtime(config_file)) if os.path.exists(config_file) else None
        }
    
    return status

def check_models():
    """V√©rifie les mod√®les entra√Æn√©s."""
    models_dir = Path("models")
    models_status = {}
    
    if models_dir.exists():
        for model_file in models_dir.glob("*.zip"):
            stat = model_file.stat()
            models_status[model_file.name] = {
                'size_mb': stat.st_size / (1024 * 1024),
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'age_hours': (datetime.now() - datetime.fromtimestamp(stat.st_mtime)).total_seconds() / 3600
            }
    
    return models_status

def check_logs():
    """V√©rifie les logs r√©cents."""
    log_files = list(Path(".").glob("training_*.log")) + list(Path(".").glob("*.log"))
    recent_logs = []
    
    for log_file in log_files:
        stat = log_file.stat()
        age_hours = (datetime.now() - datetime.fromtimestamp(stat.st_mtime)).total_seconds() / 3600
        
        if age_hours < 24:  # Logs des derni√®res 24h
            recent_logs.append({
                'name': log_file.name,
                'size_mb': stat.st_size / (1024 * 1024),
                'age_hours': age_hours
            })
    
    return sorted(recent_logs, key=lambda x: x['age_hours'])

def get_system_performance():
    """Analyse les performances syst√®me."""
    perf = {}
    
    # Utilisation disque
    try:
        import shutil
        total, used, free = shutil.disk_usage(".")
        perf['disk'] = {
            'total_gb': total / (1024**3),
            'used_gb': used / (1024**3),
            'free_gb': free / (1024**3),
            'usage_pct': (used / total) * 100
        }
    except:
        perf['disk'] = None
    
    # M√©moire (approximation via fichiers temporaires)
    try:
        import psutil
        mem = psutil.virtual_memory()
        perf['memory'] = {
            'total_gb': mem.total / (1024**3),
            'available_gb': mem.available / (1024**3),
            'usage_pct': mem.percent
        }
    except:
        perf['memory'] = None
    
    return perf

def analyze_last_training():
    """Analyse le dernier entra√Ænement."""
    logs = check_logs()
    if not logs:
        return None
    
    # Prendre le log le plus r√©cent
    latest_log = logs[0]['name']
    
    try:
        with open(latest_log, 'r') as f:
            content = f.read()
        
        analysis = {}
        
        # Rechercher des m√©triques
        if "Capital:" in content:
            lines = content.split('\n')
            capital_lines = [l for l in lines if "Capital:" in l and "$" in l]
            if capital_lines:
                try:
                    last_capital_line = capital_lines[-1]
                    capital_part = last_capital_line.split("Capital:")[1].split()[0]
                    analysis['final_capital'] = float(capital_part.replace("$", "").replace(",", ""))
                except:
                    pass
        
        if "ROI:" in content:
            lines = content.split('\n')
            roi_lines = [l for l in lines if "ROI:" in l and "%" in l]
            if roi_lines:
                try:
                    last_roi_line = roi_lines[-1]
                    roi_part = last_roi_line.split("ROI:")[1].split("%")[0].strip()
                    analysis['roi_pct'] = float(roi_part.replace("+", ""))
                except:
                    pass
        
        if "timesteps" in content.lower():
            if "5000" in content or "5,000" in content:
                analysis['training_size'] = "Quick (5K)"
            elif "50000" in content or "50,000" in content:
                analysis['training_size'] = "Standard (50K)"
            elif "100000" in content or "100,000" in content:
                analysis['training_size'] = "Extended (100K)"
            else:
                analysis['training_size'] = "Custom"
        
        analysis['log_age_hours'] = logs[0]['age_hours']
        
        return analysis
        
    except Exception as e:
        return None

def create_status_report():
    """Cr√©e le rapport de statut complet."""
    
    # En-t√™te principal
    console.print(Rule("[bold blue]üöÄ ADAN Trading Agent - Status Report[/bold blue]", style="blue"))
    console.print(f"[dim]G√©n√©r√© le: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}[/dim]\n")
    
    # 1. √âtat de l'environnement
    env_table = Table(title="üîß Environnement Syst√®me", title_style="bold green")
    env_table.add_column("Composant", style="dim cyan")
    env_table.add_column("Status", style="bright_white")
    env_table.add_column("D√©tails", style="dim")
    
    # Conda
    conda_ok = check_conda_env()
    env_table.add_row(
        "Conda Environment", 
        "‚úÖ OK" if conda_ok else "‚ùå MANQUANT",
        "trading_env actif" if conda_ok else "Ex√©cuter: conda activate trading_env"
    )
    
    # Python
    python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
    env_table.add_row("Python Version", f"‚úÖ {python_version}", "Compatible")
    
    # R√©pertoire de travail
    current_dir = os.path.basename(os.getcwd())
    env_table.add_row("Working Directory", f"‚úÖ {current_dir}", f"Path: {os.getcwd()}")
    
    console.print(env_table)
    console.print()
    
    # 2. √âtat des donn√©es
    data_status = check_data_files()
    
    data_table = Table(title="üìä √âtat des Donn√©es", title_style="bold cyan")
    data_table.add_column("Type", style="dim cyan")
    data_table.add_column("Fichiers", style="bright_white")
    data_table.add_column("Taille", style="green")
    data_table.add_column("Status", style="bright_white")
    
    # Donn√©es source
    source_status = "‚úÖ COMPLET" if data_status['source']['files'] == data_status['source']['total'] else "‚ö†Ô∏è PARTIEL"
    data_table.add_row(
        "Donn√©es Source",
        f"{data_status['source']['files']}/{data_status['source']['total']}",
        f"{data_status['source']['size_mb']:.1f} MB",
        source_status
    )
    
    # Donn√©es trait√©es  
    processed_status = "‚úÖ PR√äT" if data_status['processed']['files'] == data_status['processed']['total'] else "‚ùå MANQUANT"
    data_table.add_row(
        "Donn√©es Trait√©es",
        f"{data_status['processed']['files']}/{data_status['processed']['total']}",
        f"{data_status['processed']['size_mb']:.1f} MB", 
        processed_status
    )
    
    console.print(data_table)
    console.print()
    
    # 3. Configuration
    config_status = check_config_files()
    
    config_table = Table(title="‚öôÔ∏è Configuration", title_style="bold yellow")
    config_table.add_column("Fichier", style="dim cyan")
    config_table.add_column("Status", style="bright_white")
    config_table.add_column("Taille", style="dim")
    
    for config_name, info in config_status.items():
        if info['exists']:
            status = "‚úÖ OK"
            size = f"{info['size']} bytes"
        else:
            status = "‚ùå MANQUANT"
            size = "-"
        
        config_table.add_row(config_name, status, size)
    
    console.print(config_table)
    console.print()
    
    # 4. Mod√®les entra√Æn√©s
    models = check_models()
    
    if models:
        models_table = Table(title="ü§ñ Mod√®les Entra√Æn√©s", title_style="bold magenta")
        models_table.add_column("Mod√®le", style="dim cyan")
        models_table.add_column("Taille", style="bright_white")
        models_table.add_column("√Çge", style="green")
        models_table.add_column("Derni√®re Modif", style="dim")
        
        for model_name, info in sorted(models.items(), key=lambda x: x[1]['modified'], reverse=True):
            age_text = f"{info['age_hours']:.1f}h" if info['age_hours'] < 24 else f"{info['age_hours']/24:.1f}j"
            models_table.add_row(
                model_name,
                f"{info['size_mb']:.1f} MB",
                age_text,
                info['modified'].strftime('%H:%M')
            )
        
        console.print(models_table)
    else:
        console.print(Panel("[yellow]‚ùå Aucun mod√®le entra√Æn√© trouv√©[/yellow]", title="ü§ñ Mod√®les"))
    
    console.print()
    
    # 5. Analyse du dernier entra√Ænement
    training_analysis = analyze_last_training()
    
    if training_analysis:
        perf_table = Table(title="üìà Derni√®re Performance", title_style="bold green")
        perf_table.add_column("M√©trique", style="dim cyan")
        perf_table.add_column("Valeur", style="bright_white")
        perf_table.add_column("√âvaluation", style="green")
        
        if 'final_capital' in training_analysis:
            capital = training_analysis['final_capital']
            if capital >= 20:
                eval_text = "üèÜ EXCELLENT"
            elif capital >= 15:
                eval_text = "‚úÖ BON"
            elif capital >= 10:
                eval_text = "‚ö†Ô∏è ACCEPTABLE"
            else:
                eval_text = "‚ùå FAIBLE"
            
            perf_table.add_row("Capital Final", f"${capital:.2f}", eval_text)
        
        if 'roi_pct' in training_analysis:
            roi = training_analysis['roi_pct']
            if roi >= 20:
                eval_text = "üöÄ EXCEPTIONNEL"
            elif roi >= 0:
                eval_text = "üìà POSITIF"
            elif roi >= -20:
                eval_text = "‚ö†Ô∏è TOL√âRABLE"
            else:
                eval_text = "üìâ CRITIQUE"
            
            perf_table.add_row("ROI", f"{roi:+.2f}%", eval_text)
        
        if 'training_size' in training_analysis:
            perf_table.add_row("Taille Entra√Ænement", training_analysis['training_size'], "‚ÑπÔ∏è INFO")
        
        if 'log_age_hours' in training_analysis:
            age_text = f"{training_analysis['log_age_hours']:.1f}h ago"
            perf_table.add_row("Derni√®re Session", age_text, "‚è∞ R√âCENT" if training_analysis['log_age_hours'] < 2 else "üìÖ ANCIEN")
        
        console.print(perf_table)
    else:
        console.print(Panel("[yellow]‚ùå Aucune donn√©e d'entra√Ænement r√©cente trouv√©e[/yellow]", title="üìà Performance"))
    
    console.print()
    
    # 6. Recommandations
    recommendations = []
    
    # Analyser les probl√®mes et g√©n√©rer des recommandations
    if not conda_ok:
        recommendations.append("üîß Activer l'environnement conda: conda activate trading_env")
    
    if data_status['processed']['files'] < data_status['processed']['total']:
        recommendations.append("üìä G√©n√©rer les donn√©es manquantes: python scripts/convert_real_data.py --exec_profile cpu")
    
    if not models:
        recommendations.append("üöÄ D√©marrer un premier entra√Ænement: python scripts/train_rl_agent.py --exec_profile cpu --total_timesteps 5000 --initial_capital 15.0")
    
    if training_analysis and 'final_capital' in training_analysis and training_analysis['final_capital'] < 10:
        recommendations.append("‚ö†Ô∏è Performances faibles - Augmenter le nombre de timesteps ou ajuster les param√®tres")
    
    if not recommendations:
        recommendations.append("‚úÖ Syst√®me op√©rationnel - Pr√™t pour l'entra√Ænement de production!")
    
    # Afficher les recommandations
    if recommendations:
        rec_panel = Panel(
            "\n".join(f"{i+1}. {rec}" for i, rec in enumerate(recommendations)),
            title="üí° Recommandations",
            border_style="green"
        )
        console.print(rec_panel)
    
    console.print()
    
    # 7. Commandes rapides
    quick_commands = [
        ("Entra√Ænement Rapide", "python scripts/train_rl_agent.py --exec_profile cpu --total_timesteps 5000 --initial_capital 15.0"),
        ("Entra√Ænement Standard", "python scripts/train_rl_agent.py --exec_profile cpu --total_timesteps 50000 --initial_capital 15.0"),
        ("√âvaluation Mod√®le", "python scripts/quick_eval.py --model_path models/final_model.zip --profile cpu --capital 15.0"),
        ("Lancement Automatis√©", "python run_adan.py --mode auto --quick --capital 15.0"),
        ("Monitoring Temps R√©el", "python scripts/monitor_training.py")
    ]
    
    commands_table = Table(title="‚ö° Commandes Rapides", title_style="bold blue")
    commands_table.add_column("Action", style="dim cyan")
    commands_table.add_column("Commande", style="bright_white")
    
    for action, command in quick_commands:
        commands_table.add_row(action, f"[dim]{command}[/dim]")
    
    console.print(commands_table)
    
    # Footer
    console.print()
    console.print(Rule("[dim]ADAN Trading Agent - Syst√®me de Trading Automatis√© avec IA[/dim]", style="dim"))

def main():
    try:
        create_status_report()
        return 0
    except Exception as e:
        console.print(f"[red]‚ùå Erreur lors de la g√©n√©ration du rapport: {str(e)}[/red]")
        return 1

if __name__ == "__main__":
    sys.exit(main())